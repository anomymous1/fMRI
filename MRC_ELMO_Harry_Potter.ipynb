{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "tf.reset_default_graph()\n",
    "#embed1 = hub.Module(\"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/1\")\n",
    "#embed3= hub.Module(\"https://tfhub.dev/google/universal-sentence-encoder-large/2\")\n",
    "embed3=hub.Module(\"https://tfhub.dev/google/elmo/2\")\n",
    "messages = tf.placeholder(dtype=tf.string, shape=[None])\n",
    "output = embed3(messages,as_dict=True)\n",
    "#tf.reset_default_graph()\n",
    "session=tf.Session()\n",
    "session.run([tf.global_variables_initializer(), tf.tables_initializer()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=[]\n",
    "with open(\"Tokens_Harry_Potter.csv\") as f:\n",
    "    for line in f:\n",
    "        \n",
    "        firstchar = line.strip()[0]\n",
    "        if(firstchar in \"[\\\"\"):\n",
    "            line_strip =line.strip().strip(\"\\\"\").strip('[]').replace(\"\\\"\\\"\",\"\\\"\")\n",
    "            text.append(line_strip)\n",
    "            \n",
    "\n",
    "import nltk\n",
    "sentences=nltk.sent_tokenize(\" \".join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for i in range(0,len(sentences)):\n",
    "    results.append(session.run(output,feed_dict={messages:[sentences[i]]}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_words_embeddings=[]\n",
    "for sentence,result in zip(sentences,results):\n",
    "    for word,embedding in zip(sentence.split(),result[\"elmo\"][0]):\n",
    "        map_words_embeddings.append({\"word\":word\n",
    "                                    ,\"embb\":embedding})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_index = 0\n",
    "with open(\"Tokens_Harry_Potter.csv\") as f,open(\"Tokens_with_embedding_new.txt\",\"w\") as output:\n",
    "    for line in f:\n",
    "        \n",
    "        firstchar = line.strip()[0]\n",
    "        if(firstchar in \"[\\\"\"):\n",
    "            line_strip = line.strip().strip(\"\\\"\").strip('[]').replace(\"\\\"\\\"\",\"\\\"\")\n",
    "            text.append(line_strip)\n",
    "            if(line_strip == map_words_embeddings[text_index][\"word\"]):\n",
    "                \n",
    "                print(line.strip(),\",\".join([str(x) for x in map_words_embeddings[text_index][\"embb\"]]),sep=\"\\t\",file = output)\n",
    "            else:\n",
    "                print(\"worried?\")\n",
    "            text_index += 1\n",
    "        else:\n",
    "            print(line.strip(),file = output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "mrc_data=pd.read_csv(\"Bootstrapped_Psycholinguistic_Features.txt\",sep=\"\\t\")\n",
    "words_mrc={}\n",
    "for i in range(1,85943):\n",
    "    words_mrc[mrc_data.iloc[i].Word] = {key:mrc_data.iloc[i][key]\n",
    "                                          for key in [\"Familiarity\"\n",
    "                                                      ,\"Age of Acquisition\"\n",
    "                                                      ,\"Concreteness\"\n",
    "                                                      ,\"Imagery\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Tokens_Harry_Potter.csv\") as f,open(\"Tokens_with_mrc.txt\",\"w\") as output:\n",
    "    for line in f:\n",
    "        \n",
    "        firstchar = line.strip()[0]\n",
    "        if(firstchar in \"[\\\"\"):\n",
    "            line_strip = line.strip().strip(\"\\\"\").strip('[]').replace(\"\\\"\\\"\",\"\\\"\")\n",
    "            text.append(line_strip)\n",
    "            word_strip=line_strip.lower().strip(\"\\\".,!?:\")\n",
    "            if(word_strip in words_mrc):\n",
    "                \n",
    "                print(line.strip()\n",
    "                      ,words_mrc[word_strip][\"Familiarity\"]\n",
    "                      ,words_mrc[word_strip][\"Age of Acquisition\"]\n",
    "                      ,words_mrc[word_strip][\"Concreteness\"]\n",
    "                      ,words_mrc[word_strip][\"Familiarity\"]\n",
    "                      ,sep=\"\\t\"\n",
    "                      ,file = output)\n",
    "            else:\n",
    "                print(line.strip()\n",
    "                      ,\"NA\"\n",
    "                      ,\"NA\"\n",
    "                      ,\"NA\"\n",
    "                      ,\"NA\"\n",
    "                      ,sep=\"\\t\"\n",
    "                      ,file = output)\n",
    "                print(\"worried?\",line_strip)\n",
    "            text_index += 1\n",
    "        else:\n",
    "            print(line.strip(),file = output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
