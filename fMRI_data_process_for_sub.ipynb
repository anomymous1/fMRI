{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This program transforms fMRI subject data to NLP input-able feature data\n",
    "##\n",
    "## 1. Assume import subject data is at the root directory of this program.\n",
    "## 2. To run this program, setup the {file directory} and {output directory} in your local harddrive.\n",
    "## 3. ultimate output file is named as \"word_feature_gauss_region_XX.txt\" which XX indicates the region number\n",
    "## 4. output file is delimited by ~ between voxels since other common charaters are already included in story context\n",
    "## 5. depends on your model program, you may need to convert output file to other format.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.signal as sg\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fMRI_initiate(file_name):\n",
    "    subject = loadmat(file_name)\n",
    "    time = subject['time']\n",
    "    data = subject['data']\n",
    "    meta = subject['meta']\n",
    "    words = subject['words']\n",
    "    \n",
    "    result = {\n",
    "        'time': time,\n",
    "        'data': data,\n",
    "        'meta': meta,\n",
    "        'words': words\n",
    "    }\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fMRI_data_by_region(data, meta, output_to_file = False):\n",
    "    ## subject_data\n",
    "    ## subject_meta\n",
    "    meta['colToROInum'][0,0][0].shape[0]\n",
    "    ROI_map = {}\n",
    "    for index, x in np.ndenumerate(meta['colToROInum'][0,0][0]):\n",
    "        if str(x) in ROI_map:\n",
    "            ROI_map.get(str(x)).append(index[0])\n",
    "        else:\n",
    "            ROI_map[str(x)] = [index[0]]\n",
    "    file_paths = []\n",
    "    region_nums = []\n",
    "    file_directory = \"{file directory}\" ##setup own directory\n",
    "    file_prefix = \"raw_region_\"\n",
    "    file_format = \".txt\"\n",
    "    for key in ROI_map.keys():\n",
    "        region_data = data[:, ROI_map[str(key)]]\n",
    "        assert(region_data.shape[1] == len(ROI_map[str(key)]))\n",
    "        \n",
    "        if output_to_file == True:\n",
    "            out_path = file_directory + file_prefix + str(key) + file_format\n",
    "            region_nums.append(key)\n",
    "            np.savetxt(out_path, region_data,delimiter='~',fmt=\"%s\")\n",
    "    \n",
    "    result = {\n",
    "        'ROI_map': ROI_map,\n",
    "        'file_directory': file_directory,\n",
    "        'file_prefix': file_prefix,\n",
    "        'file_format': file_format,\n",
    "        'region_nums': region_nums\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get words and its length, start time and duration\n",
    "def get_words_start_time(words):\n",
    "    count_records = words.shape[1]\n",
    "    array_records = [];\n",
    "    for i in range(count_records):\n",
    "        single_row = words[0,i]\n",
    "        transfer_row = np.array([\"[\" + single_row[0][0,0][0] + \"]\", len(single_row[0][0,0][0]), single_row[1][0,0], single_row[2][0,0]])\n",
    "        array_records.append(transfer_row)\n",
    "    return  np.array(array_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fourfold copy data and expand time from 0,2 --> 0,0.5,1,1.5,2\n",
    "def get_data_time_fourfold(data, time):\n",
    "    subject_data_time =  np.concatenate((time, data), axis=1)\n",
    "    subject_data_time = subject_data_time.astype(np.object)\n",
    "    subject_data_time_fourfold = []\n",
    "    for i in range(subject_data_time.shape[0]):\n",
    "        temp = subject_data_time[i,:].copy()\n",
    "        row_05 = temp.copy()\n",
    "        row_05[0] += 0.5\n",
    "        row_10 = temp.copy()\n",
    "        row_10[0] += 1\n",
    "        row_15 = temp.copy()\n",
    "        row_15[0] += 1.5\n",
    "        subject_data_time_fourfold.append(temp)\n",
    "        subject_data_time_fourfold.append(row_05)\n",
    "        subject_data_time_fourfold.append(row_10)\n",
    "        subject_data_time_fourfold.append(row_15)\n",
    "    subject_data_time_fourfold = np.array(subject_data_time_fourfold)\n",
    "    \n",
    "    for i in range(subject_data_time_fourfold.shape[0]-1):\n",
    "        assert(subject_data_time_fourfold[i,0] == subject_data_time_fourfold[i+1, 0]-0.5)\n",
    "    \n",
    "    subject_data_time_fourfold_time = subject_data_time_fourfold[:,0:2] ## time - fourfold 0,0.5,1,1.5,2 ... \n",
    "    subject_data_time_fourfold_data = subject_data_time_fourfold[:,2:]  ## data - fourfold.\n",
    "    \n",
    "    assert(subject_data_time_fourfold_time.shape[0] == time.shape[0] * 4)\n",
    "    assert(subject_data_time_fourfold_data.shape[0] == data.shape[0] * 4)\n",
    "    assert(subject_data_time_fourfold_data.shape[1] == data.shape[1])\n",
    "    \n",
    "    result = {\n",
    "        'fourfold_time': subject_data_time_fourfold_time,\n",
    "        'fourfold_data': subject_data_time_fourfold_data\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalize fourfold data to be between 0 and 1 and round to certain decimals\n",
    "def data_fourfold_normalize_round(data, dmax, dmin, round_scale=5):\n",
    "    result = (data - dmin) / (dmax - dmin)\n",
    "    result_round = np.around(result.astype(np.double), decimals=round_scale)\n",
    "    return result_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_word_time_data(words, time, data):\n",
    "    ## words: word_start_time\n",
    "    ## time: fourfold_time,\n",
    "    ## data: fourfold_data_normalized\n",
    "    assert(time.shape[0] == data.shape[0])\n",
    "    words.astype(np.object)\n",
    "    time_data = np.concatenate((time, data), axis=1)\n",
    "    result = []\n",
    "    i = 0 # pointer for words [time has gap]\n",
    "    j = 0 # pointer for time_data [time has no gap]\n",
    "    while i < len(words) and j < len(time_data):\n",
    "        if float(words[i,2]) == float(time_data[j,0]):\n",
    "            word_time_data = np.append(words[i], time_data[j])\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif float(words[i,2]) > float(time_data[j,0]):\n",
    "            word_time_data = np.append(np.zeros(words.shape[1]), time_data[j])\n",
    "            j += 1\n",
    "        else:\n",
    "            print('Code goes to unexpected block for i: ' + str(i) + \", j: \"+str(j))\n",
    "            word_time_data = np.append(words[i], np.zeros(time_data[j]))\n",
    "            i += 1\n",
    "        #result[j] = word_time_data\n",
    "        result.append(word_time_data)\n",
    "    while j < len(time_data):\n",
    "        word_time_data = np.append(np.zeros(words.shape[1]), time_data[j])\n",
    "        j += 1\n",
    "        result.append(word_time_data)\n",
    "        \n",
    "    result = np.array(result)\n",
    "    #assert(result.shape[0] == time_data.shape[0])\n",
    "    #assert(result.shape[1] == words.shape[1] + time_data.shape[1])\n",
    "\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def apply_gauss_window(data_start_col, data, window_size, delay = 0, round_scale=4):\n",
    "    ## apply gaussian weights to data, assume data file has no \"header\"\n",
    "    weights = sg.gaussian(window_size,1); ## 1 = deviation\n",
    "    \n",
    "    meta = data[:,0:data_start_col]\n",
    "    pure_data = data[:,data_start_col:].astype(np.float)\n",
    "    \n",
    "    result = []\n",
    "    for row in range(pure_data.shape[0]-window_size-1):\n",
    "        weight_sum = np.zeros(pure_data.shape[1])\n",
    "        for i in range(window_size):\n",
    "            weight_sum = weight_sum + pure_data[row+delay+i] * weights[i]\n",
    "        weight_avg = weight_sum / window_size \n",
    "        result.append(weight_avg)\n",
    "    result = np.array(result)\n",
    "    assert(result.shape[0] == data.shape[0] - window_size -1)\n",
    "    assert(result.shape[1] == pure_data.shape[1])\n",
    "    \n",
    "    result = np.round(result, round_scale)\n",
    "    output_result = np.concatenate((meta[0:result.shape[0]], result), axis = 1)\n",
    "    return output_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_header_for_region_features(word_feature_data, dataShape, region_num):\n",
    "    ## this function only add header for particular region word features\n",
    "    meta_col = ['token', 'length', 'start_time', 'duration', 'start_time2', 'section']\n",
    "    assert(len(meta_col) + dataShape == word_feature_data.shape[1])\n",
    "    for i in range(dataShape):\n",
    "        meta_col.append(str(region_num) + '_v' + str(i+1))\n",
    "    assert(len(meta_col) == word_feature_data.shape[1])\n",
    "    result = np.concatenate((np.array(meta_col).reshape((1, word_feature_data.shape[1])), word_feature_data), axis=0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fMRI_process(file, gauss_window_size = 12):\n",
    "    ## umbrella method to call all methods\n",
    "    subject = fMRI_initiate(file)\n",
    "    subject_words = subject['words']\n",
    "    subject_time = subject['time']\n",
    "    subject_data = subject['data']\n",
    "    subject_meta = subject['meta']\n",
    "    \n",
    "    dmax, dmin = subject_data.max(), subject_data.min()\n",
    "    print(\"File name: \" + str(file))\n",
    "    print(\"max value : \" + str(dmax) + \"; min value: \" + str(dmin))\n",
    "    print('gauss weights for window size : '+ str(gauss_window_size) + ' is: ' + str(sg.gaussian(gauss_window_size,1)))\n",
    "    \n",
    "    ## get words with start time and duration\n",
    "    words_start_time = get_words_start_time(subject_words)\n",
    "    \n",
    "    #split raw data by region and write to harddrive\n",
    "    region_info = fMRI_data_by_region(subject_data, subject_meta, output_to_file = True)\n",
    "    region_nums = region_info['region_nums']\n",
    "    region_ROI_map = region_info['ROI_map']\n",
    "    region_file_directory = region_info['file_directory']\n",
    "    region_file_prefix = region_info['file_prefix']\n",
    "    region_file_format = region_info['file_format']\n",
    "          \n",
    "    #load raw data by region\n",
    "    for region_num in region_nums:\n",
    "        input_file = region_file_directory + region_file_prefix + str(region_num) + region_file_format\n",
    "        region_data = np.loadtxt(open(input_file, \"rb\"), delimiter=\"~\")\n",
    "        assert(region_data.shape[0] == subject_data.shape[0])\n",
    "        assert(region_data.shape[1] == len(region_ROI_map.get(str(region_num))))\n",
    "        \n",
    "        fourfold = get_data_time_fourfold(region_data, subject_time) ## fourfold\n",
    "        \n",
    "        fourfold_time = fourfold['fourfold_time']\n",
    "        fourfold_data = fourfold['fourfold_data']\n",
    "        \n",
    "        del fourfold\n",
    "        \n",
    "        fourfold_data_norm = data_fourfold_normalize_round(fourfold_data, dmax, dmin, round_scale=6)\n",
    "        \n",
    "        raw_merge_result = merge_word_time_data(words_start_time, fourfold_time, fourfold_data)\n",
    "        fine_merge_result = merge_word_time_data(words_start_time, fourfold_time, fourfold_data_norm)\n",
    "        \n",
    "        ## word feature for raw data\n",
    "        raw_out_file = \"{output directory}/word_feature_raw_region_\" + str(region_num) + \".txt\"\n",
    "        raw_merge_result_with_header = build_header_for_region_features(raw_merge_result, fourfold_data.shape[1], region_num)\n",
    "        np.savetxt(raw_out_file, raw_merge_result_with_header, delimiter='~',fmt=\"%s\")\n",
    "        del raw_merge_result_with_header\n",
    "        del raw_merge_result\n",
    "        \n",
    "        ## word feature for normalized data\n",
    "        fine_out_file = \"{output directory}/word_feature_norm_region_\" + str(region_num) + \".txt\"\n",
    "        fine_merge_result_with_header = build_header_for_region_features(fine_merge_result, fourfold_data.shape[1], region_num)\n",
    "        np.savetxt(fine_out_file, fine_merge_result_with_header, delimiter='~',fmt=\"%s\")\n",
    "        del fine_merge_result_with_header\n",
    "        \n",
    "        ## word feature with Gaussian Window\n",
    "        gauss_out_file = \"{output directory}/word_feature_gauss_region_\" + str(region_num) + \".txt\"\n",
    "        data_start_index = words_start_time.shape[1] + fourfold_time.shape[1]\n",
    "        gauss_merge_result = apply_gauss_window(data_start_index, fine_merge_result, window_size = gauss_window_size, delay = 0, round_scale = 4)\n",
    "        gauss_merge_result_with_header = build_header_for_region_features(gauss_merge_result, fourfold_data.shape[1], region_num)\n",
    "        np.savetxt(gauss_out_file, gauss_merge_result_with_header, delimiter='~',fmt=\"%s\")\n",
    "        \n",
    "    print('Done processing fMRI data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name: subject_8.mat\n",
      "max value : 1140; min value: -81\n",
      "gauss weights for window size : 12 is: [2.69957850e-07 4.00652974e-05 2.18749112e-03 4.39369336e-02\n",
      " 3.24652467e-01 8.82496903e-01 8.82496903e-01 3.24652467e-01\n",
      " 4.39369336e-02 2.18749112e-03 4.00652974e-05 2.69957850e-07]\n",
      "Done processing fMRI data\n"
     ]
    }
   ],
   "source": [
    "fMRI_process(file = 'subject_8.mat', gauss_window_size = 12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
